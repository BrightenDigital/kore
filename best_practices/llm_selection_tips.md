# ü§ñ LLM Selection Tips

Choosing the right Large Language Model (LLM) for your task can significantly impact the quality, speed, and creativity of your results. Compass supports multiple LLMs, each with their own strengths and ideal use cases.

## Available LLMs

Below the agents selectors on the right side of your interface, you'll find options to change the LLM being used to run your team.

## Recommended Models

### Deepseek Chat üèÉ‚Äç‚ôÄÔ∏è

**Best for**: Everyday development tasks

- Efficient code generation
- Quick responses
- Standard development patterns

**When to use**: Standard feature implementation, bug fixes, and routine development tasks

### Sonnet 3.7 üí≠

**Best for**: Demanding tasks requiring creative thinking

- Complex problem-solving
- Novel approaches to challenges
- Deeper reasoning capabilities

**When to use**: Architecture design, optimizing algorithms, solving complex edge cases, or when you need outside-the-box thinking

### GPT-4.1 ‚ö°

**Best for**: Balance of speed and quality

- Relatively fast considering its capabilities
- Strong all-around performance
- Good code quality

**When to use**: When you need quality results with reasonable speed

### Gemini üé≤

**Best for**: Exploration and experimentation

- A "box full of surprises"
- Alternative approaches
- Diverse solutions

**When to use**: When you want to explore different implementation possibilities or creative solutions

## Switching Models Mid-Project

You can change the LLM at any point in your project:

1. Select a different model from the dropdown
2. Continue with your requests as normal

This flexibility allows you to:

- Use faster models for initial development
- Switch to more capable models for complex challenges
- Experiment with different approaches

## Performance Considerations

- Response time varies significantly between models
- More powerful models may take longer to generate responses
- Consider task complexity when selecting a model to balance speed and quality

Remember that the "best" LLM depends on your specific task, timeline, and quality requirements. Don't hesitate to experiment with different models to find what works best for your workflow!